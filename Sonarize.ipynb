{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéß Sonarize ‚Äì Transcri√ß√£o e Resumo de √Åudios do YouTube\n",
    "\n",
    "Este notebook implementa um pipeline completo para:\n",
    "\n",
    "1. **Baixar o √°udio** de um v√≠deo do YouTube usando a biblioteca `pytubefix`.\n",
    "2. **Transcrever o √°udio** automaticamente com o modelo Whisper da OpenAI.\n",
    "3. **Gerar um resumo inteligente** da transcri√ß√£o utilizando a API do Google Gemini.\n",
    "\n",
    "## üìå Funcionalidades\n",
    "\n",
    "- Download r√°pido do √°udio em formato `.m4a`.\n",
    "- Transcri√ß√£o precisa com suporte ao idioma portugu√™s.\n",
    "- Resumo autom√°tico do conte√∫do transcrito com IA generativa.\n",
    "\n",
    "## üöÄ Como usar\n",
    "\n",
    "Basta executar as c√©lulas sequencialmente e fornecer a URL do v√≠deo quando solicitado.\n",
    "\n",
    "---\n",
    "\n",
    "**Observa√ß√£o:** Lembre-se de substituir `\"SUA_API_KEY_AQUI\"` pela sua chave de API do Google Gemini na terceira c√©lula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T17:50:37.759573300Z",
     "start_time": "2026-02-16T17:50:27.079159600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 8642,
     "status": "ok",
     "timestamp": 1771178590223,
     "user": {
      "displayName": "Davi Bezerra Fraga",
      "userId": "04037313869542615130"
     },
     "user_tz": 180
    },
    "id": "s_KaWpOPMh_u",
    "outputId": "487b9c16-1aa9-442f-b4a6-7e91d85098c2"
   },
   "outputs": [],
   "source": [
    "# Importa√ß√µes\n",
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "\n",
    "# Entrada do usu√°rio\n",
    "url = input(\"üîó Digite a url: \")\n",
    "\n",
    "# Cria√ß√£o do objeto YouTube\n",
    "yt = YouTube(url, on_progress_callback=on_progress)\n",
    "\n",
    "\n",
    "# Exibi√ß√£o das informa√ß√µes do v√≠deo\n",
    "print(f\"\\nüìπ T√≠tulo: {yt.title}\")\n",
    "print(f\"‚è±Ô∏è Dura√ß√£o: {yt.length} segundos\")\n",
    "print(f\"üë§ Autor: {yt.author}\")\n",
    "\n",
    "# Download do √°udio\n",
    "print(\"\\nüîÑ Iniciando download do √°udio...\")\n",
    "ys = yt.streams.get_audio_only()\n",
    "ys.download(filename=\"audioyt.m4a\")\n",
    "print('‚úÖ Download conclu√≠do!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T17:53:28.862470200Z",
     "start_time": "2026-02-16T17:50:37.822071100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "executionInfo": {
     "elapsed": 5738,
     "status": "error",
     "timestamp": 1771178600426,
     "user": {
      "displayName": "Davi Bezerra Fraga",
      "userId": "04037313869542615130"
     },
     "user_tz": 180
    },
    "id": "IcJ9W3reRQX6",
    "outputId": "c19cba63-7845-4e46-8722-21fb9392064c"
   },
   "outputs": [],
   "source": [
    "# Importa√ß√£o da biblioteca Whisper (reconhecimento de fala da OpenAI)\n",
    "import whisper\n",
    "\n",
    "# Carrega o modelo \"base\" (equilibrado entre velocidade e precis√£o)\n",
    "# Outras op√ß√µes: tiny, small, medium, large\n",
    "modelo = whisper.load_model(\"base\")\n",
    "\n",
    "\n",
    "resultado = modelo.transcribe(\"audioyt.m4a\",   # Transcreve o arquivo de √°udio \"audioyt.m4a\"\n",
    "                              fp16=False,      # fp16=False: desativa precis√£o reduzida (compatibilidade)\n",
    "                              language =\"pt\")  # language=\"pt\": for√ßa o idioma portugu√™s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"transcricao.txt\",         # Salva a transcri√ß√£o em um arquivo de texto\n",
    "          \"w\",                       # \"w\": modo escrita\n",
    "          encoding=\"utf-8\") as f:    # encoding=\"utf-8\": suporte a caracteres especiais\n",
    "    # resultado[\"text\"] cont√©m o texto transcrito\n",
    "    f.write(resultado[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T17:53:48.507132100Z",
     "start_time": "2026-02-16T17:53:28.878117200Z"
    },
    "id": "mobwEicaZF_V"
   },
   "outputs": [],
   "source": [
    "# Importa√ß√£o da biblioteca Google Gemini AI\n",
    "from google import genai\n",
    "\n",
    "\n",
    "# Abre e l√™ o arquivo de transcri√ß√£o criado anteriormente\n",
    "with open('transcricao.txt', 'r') as arquivo:\n",
    "    conteudo = arquivo.read() # L√™ todo o conte√∫do do arquivo\n",
    "    # Cria uma pergunta/prompt para a IA\n",
    "    pergunta = f\"\"\"\n",
    "Fa√ßa um resumo breve do\n",
    "contedudo: {conteudo}\n",
    "\"\"\"\n",
    "\n",
    "# Cria cliente com sua chave de API (autentica√ß√£o)\n",
    "# Substitua \"SUA_API_KEY_AQUI\" pela sua chave real\n",
    "genai.Client(api_key=\"SUA_API_KEY_AQUI\")\n",
    "\n",
    "# Envia a pergunta para o modelo Gemini\n",
    "# model='gemini-flash-lite-latest': modelo r√°pido e leve\n",
    "# contents=pergunta: o prompt que criamos\n",
    "response = genai.GenerativeModel('gemini-flash-lite-latest').generate_content(       \n",
    "     contents=pergunta                       \n",
    ")\n",
    "\n",
    "\n",
    "# Extrai e exibe a resposta gerada\n",
    "resp = response.text                 # Pega o texto da resposta\n",
    "print(resp)                          # Mostra o resumo no terminal"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOwQ+Q2H5efpsftAXVQA5lJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
